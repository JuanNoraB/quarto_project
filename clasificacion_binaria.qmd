---
title: "Clasificación Binaria - Siniestros de Tránsito Letales"
author: "Machine Learning Project"
format: 
  html:
    code-fold: true
    toc: true
    df-max-print: 10000
execute:
  warning: false
  message: false
---

# Clasificación Binaria: Predicción de Siniestros Letales

## Introducción

Este documento presenta un modelo de **clasificación binaria** para predecir si un siniestro de tránsito será letal (con fallecidos) o no letal, utilizando datos del INEC Ecuador 2019.

**Objetivo:** Desarrollar un sistema predictivo que identifique factores de riesgo asociados con la letalidad de accidentes de tránsito.

## Carga y Exploración del Dataset

```{python}
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
from sklearn.metrics import (accuracy_score, precision_score, recall_score, 
                           f1_score, confusion_matrix, classification_report, 
                           roc_curve, auc, roc_auc_score)
import warnings
warnings.filterwarnings('ignore')

# Configurar matplotlib
plt.style.use('default')
sns.set_palette("husl")

print("=== SISTEMA DE CLASIFICACIÓN BINARIA - SINIESTROS LETALES ===")
```

```{python}
# Cargar datos
df = pd.read_csv('DATOS_CLASIFICACION_BINARIA/inec_anuario-de-estadisticas-de-transporte_siniestros-de-transito_2019.csv', 
                 sep=';', encoding='utf-8')

print(f"Datos cargados: {df.shape[0]} filas, {df.shape[1]} columnas")
print("\nPrimeras 5 filas:")
df.head()
```

```{python}
# Exploración inicial
print("=== EXPLORACIÓN DE DATOS ===")
print(f"Columnas: {list(df.columns)}")
print(f"\nValores faltantes por columna:")
df.isnull().sum()
```

## Definición de la Variable Objetivo

```{python}
# Crear variable objetivo binaria
print("=== CREANDO VARIABLE OBJETIVO ===")
df['SINIESTRO_LETAL'] = (df['NUM_FALLECIDO'] > 0).astype(int)

print(f"Distribución de la variable objetivo:")
print(df['SINIESTRO_LETAL'].value_counts())
print(f"Porcentaje de siniestros letales: {df['SINIESTRO_LETAL'].mean()*100:.2f}%")

# Visualizar distribución
plt.figure(figsize=(8, 5))
df['SINIESTRO_LETAL'].value_counts().plot(kind='bar', color=['skyblue', 'salmon'])
plt.title('Distribución de Siniestros: Letales vs No Letales')
plt.xlabel('Tipo de Siniestro')
plt.ylabel('Cantidad')
plt.xticks([0, 1], ['No Letal', 'Letal'], rotation=0)
plt.show()
```

## Preparación de Features

```{python}
print("=== PREPARANDO FEATURES ===")
# Seleccionar columnas para el modelo
feature_cols = ['MES', 'DIA', 'HORA', 'PROVINCIA', 'CANTON', 'ZONA', 'CLASE', 'CAUSA']
X = df[feature_cols].copy()
y = df['SINIESTRO_LETAL']

print(f"Features seleccionadas: {feature_cols}")
print(f"Forma de X: {X.shape}")

# Procesar la columna HORA para extraer la hora numérica
def extract_hour(hora_str):
    try:
        return int(hora_str.split(':')[0])
    except:
        return 12  # valor por defecto

X['HORA_NUM'] = X['HORA'].apply(extract_hour)
X = X.drop('HORA', axis=1)

# Identificar variables categóricas y numéricas
categorical_features = ['MES', 'DIA', 'PROVINCIA', 'CANTON', 'ZONA', 'CLASE', 'CAUSA']
numerical_features = ['HORA_NUM']

print(f"Features categóricas: {categorical_features}")
print(f"Features numéricas: {numerical_features}")
```

## División de Datos

```{python}
print("=== DIVIDIENDO DATOS ===")
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print(f"Entrenamiento: {X_train.shape[0]} muestras")
print(f"Prueba: {X_test.shape[0]} muestras")
print(f"Distribución en entrenamiento:")
print(y_train.value_counts(normalize=True))
```

## Definición y Entrenamiento del Modelo

```{python}
print("=== CREANDO PIPELINE ===")
# Crear pipeline de preprocesamiento
preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numerical_features),
        ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_features)
    ])

# Pipeline completo
pipeline = Pipeline([
    ('preprocessor', preprocessor),
    ('classifier', LogisticRegression(random_state=42, max_iter=1000))
])

# Entrenar modelo
print("Entrenando modelo LogisticRegression...")
pipeline.fit(X_train, y_train)
print("✓ Modelo entrenado exitosamente")
```

## Generación de Predicciones

```{python}
print("=== REALIZANDO PREDICCIONES ===")
y_pred = pipeline.predict(X_test)
y_pred_proba = pipeline.predict_proba(X_test)[:, 1]

print(f"Predicciones generadas para {len(y_pred)} muestras")
print(f"Distribución de predicciones:")
print(pd.Series(y_pred).value_counts())
```

## Evaluación del Modelo

```{python}
print("=== EVALUACIÓN DEL MODELO ===")
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
roc_auc = roc_auc_score(y_test, y_pred_proba)

# Crear DataFrame con métricas
metricas = pd.DataFrame({
    'Métrica': ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC'],
    'Valor': [accuracy, precision, recall, f1, roc_auc],
    'Interpretación': [
        f'Clasifica correctamente el {accuracy*100:.1f}% de los casos',
        f'De los predichos como letales, {precision*100:.1f}% son realmente letales',
        f'Detecta el {recall*100:.1f}% de los siniestros letales reales',
        f'Balance entre precision y recall: {f1:.3f}',
        f'Capacidad de discriminación: {roc_auc:.3f}'
    ]
})

print(metricas.to_string(index=False))
```

```{python}
print("\nReporte de clasificación detallado:")
print(classification_report(y_test, y_pred, target_names=['No Letal', 'Letal']))
```

## Visualizaciones

### Matriz de Confusión

```{python}
plt.figure(figsize=(8, 6))
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
            xticklabels=['No Letal', 'Letal'], 
            yticklabels=['No Letal', 'Letal'])
plt.title('Matriz de Confusión - Siniestros Letales', fontsize=14, fontweight='bold')
plt.xlabel('Predicción')
plt.ylabel('Valor Real')
plt.tight_layout()
plt.show()
```

### Curva ROC

```{python}
plt.figure(figsize=(8, 6))
fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
plt.plot(fpr, tpr, color='darkorange', lw=3, label=f'ROC curve (AUC = {roc_auc:.3f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Classifier')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('Tasa de Falsos Positivos (1 - Especificidad)')
plt.ylabel('Tasa de Verdaderos Positivos (Sensibilidad)')
plt.title('Curva ROC - Clasificación de Siniestros Letales', fontsize=14, fontweight='bold')
plt.legend(loc="lower right")
plt.grid(alpha=0.3)
plt.tight_layout()
plt.show()
```

### Distribución de Probabilidades

```{python}
plt.figure(figsize=(10, 6))
plt.hist(y_pred_proba[y_test==0], bins=40, alpha=0.7, label='No Letal', color='skyblue', density=True)
plt.hist(y_pred_proba[y_test==1], bins=40, alpha=0.7, label='Letal', color='salmon', density=True)
plt.xlabel('Probabilidad Predicha de Siniestro Letal')
plt.ylabel('Densidad')
plt.title('Distribución de Probabilidades Predichas por Clase', fontsize=14, fontweight='bold')
plt.legend()
plt.grid(alpha=0.3)
plt.tight_layout()
plt.show()
```

## Análisis de Importancia de Features

```{python}
# Importancia de features (coeficientes del modelo logístico)
feature_names = (numerical_features + 
                list(pipeline.named_steps['preprocessor']
                    .named_transformers_['cat']
                    .get_feature_names_out(categorical_features)))

coefficients = pipeline.named_steps['classifier'].coef_[0]

# Crear DataFrame con importancias
feature_importance = pd.DataFrame({
    'feature': feature_names,
    'coefficient': coefficients,
    'abs_coefficient': np.abs(coefficients)
}).sort_values('abs_coefficient', ascending=False)

print("Top 10 features más importantes:")
print(feature_importance.head(10))
```

```{python}
# Visualizar top features
plt.figure(figsize=(12, 8))
top_features = feature_importance.head(15)
colors = ['red' if coef < 0 else 'green' for coef in top_features['coefficient']]
plt.barh(range(len(top_features)), top_features['coefficient'], color=colors)
plt.yticks(range(len(top_features)), top_features['feature'])
plt.xlabel('Coeficiente')
plt.title('Top 15 Features más Importantes (Coeficientes del Modelo Logístico)', fontsize=14, fontweight='bold')
plt.grid(axis='x', alpha=0.3)
plt.tight_layout()
plt.show()
```

## Interpretación de Resultados

### Rendimiento del Modelo

El modelo de clasificación binaria muestra los siguientes resultados:

- **Accuracy (92.4%)**: Excelente capacidad de clasificación general
- **ROC-AUC (0.81)**: Excelente capacidad de discriminación entre clases
- **Precision (66.1%)**: Moderada - algunos falsos positivos
- **Recall (9.9%)**: Baja - muchos siniestros letales no detectados

### Factores de Riesgo Identificados

Los factores más importantes para predecir siniestros letales incluyen:

1. **Ubicación geográfica**: Ciertos cantones y provincias muestran mayor riesgo
2. **Tipo de siniestro**: Algunas clases de accidentes son más letales que otras
3. **Causa del accidente**: Factores como exceso de velocidad o embriaguez
4. **Zona**: Diferencias entre áreas urbanas y rurales

### Limitaciones y Consideraciones

- **Clases desbalanceadas**: Solo 8% de siniestros son letales
- **Recall bajo**: El modelo es conservador, prefiere no clasificar como letal
- **Aplicación práctica**: Útil para identificar zonas y factores de alto riesgo

## Conclusiones

1. **El modelo identifica patrones geográficos** claros en la letalidad de accidentes
2. **Factores estructurales** (ubicación, tipo de vía) son más predictivos que temporales
3. **Aplicaciones en política pública**: Asignación de recursos de emergencia y prevención
4. **Mejoras futuras**: Balanceo de clases y features adicionales podrían mejorar el recall

---

*Modelo desarrollado como parte del curso de Machine Learning - Aplicación de técnicas de clasificación binaria con datos abiertos de Ecuador.*
